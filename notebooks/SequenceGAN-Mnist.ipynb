{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lrOGII_fo8xO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IuULDzz7x0Od"
   },
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 28, 28\n",
    "num_classes = 10\n",
    "img_channel = 1\n",
    "learning_rate = 1e-4\n",
    "img_shape = (WIDTH, HEIGHT, img_channel)\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-yt-7jgNx0RC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RrJ_bABhx0Tk"
   },
   "outputs": [],
   "source": [
    "encoder_inputs= layers.Input(shape=(1,))\n",
    "noise_input = layers.Input(shape=(256,))\n",
    "encoder_embedding = Embedding(10, 100, input_length=1)\n",
    "\n",
    "encoder_embeddings = encoder_embedding(encoder_inputs)\n",
    "encoder_lstm=LSTM(256, return_state=True, kernel_regularizer=l2(0.0000001), activity_regularizer=l2(0.0000001))\n",
    "LSTM_outputs, _, _ = encoder_lstm(encoder_embeddings)\n",
    "\n",
    "mul = layers.multiply([noise_input, LSTM_outputs])\n",
    "\n",
    "\n",
    "linear = layers.Dense(7*7*256, use_bias=False)(mul)\n",
    "\n",
    "batch_norm = layers.BatchNormalization()(linear)\n",
    "activation = layers.LeakyReLU()(batch_norm)\n",
    "\n",
    "reshape = layers.Reshape((7, 7, 256))(activation)\n",
    "\n",
    "x = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(reshape)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4REVA4Hyx0WD"
   },
   "outputs": [],
   "source": [
    "generator = Model([encoder_inputs,noise_input], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryzcFXJXx0YS",
    "outputId": "61a7fcea-eea5-46b8-bce8-9e7af65be8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 100)       1000        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 365568      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 256)          0           input_2[0][0]                    \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 12544)        3211264     multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 12544)        50176       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 12544)        0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 7, 7, 256)    0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 7, 7, 128)    819200      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 7, 7, 128)    512         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 7, 7, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 64)   204800      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 64)   256         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 14, 14, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 1)    1600        leaky_re_lu_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,654,376\n",
      "Trainable params: 4,628,904\n",
      "Non-trainable params: 25,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MVVgbOQYyBQq"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 2]))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "model.add(layers.LeakyReLU())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "img = layers.Input(shape=(img_shape))\n",
    "label = layers.Input(shape=(1,))\n",
    "\n",
    "embedding = layers.Embedding(10, 100, input_length = 1)(label)\n",
    "LSTM = LSTM(256, return_state=True)\n",
    "LSTM_outputs, _, _ = LSTM(embedding)\n",
    "linear = layers.Dense(28*28)(LSTM_outputs)\n",
    "label_embedding = layers.Flatten()(linear)\n",
    "label_embedding = layers.Reshape(img_shape)(label_embedding)\n",
    "\n",
    "concat = layers.Concatenate(axis=-1)([img, label_embedding])\n",
    "prediction = model(concat)\n",
    "discriminator =  Model([img, label], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZpjR2CNWyBTZ"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y6fD60BRyBWZ"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IPrKiVN1i6d7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "id": "3QevOtjFjCQZ",
    "outputId": "819c6c21-3529-4159-b19c-b2f200f10fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(\n",
    "    discriminator,\n",
    "    to_file=\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EoZ087_GyBY-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PlD4sOPk3m3F"
   },
   "outputs": [],
   "source": [
    "def save_models(epochs):\n",
    "    generator.save_weights(f'generator-epochs-{epochs}.h5')\n",
    "    discriminator.save_weihts(f'discriminator-epochs-{epochs}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ev_YrPAlKle6"
   },
   "outputs": [],
   "source": [
    "def check_cuda():\n",
    "    import tensorflow as tf\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name != '/device:GPU:0':\n",
    "        return False \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IkjhNp9531Zd"
   },
   "outputs": [],
   "source": [
    "def save_models(epochs):\n",
    "    generator.save_weights(f'generator-epochs-{epochs}.h5')\n",
    "    discriminator.save_weights(f'discriminator-epochs-{epochs}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JjElkn2AyBbl"
   },
   "outputs": [],
   "source": [
    "tf.function\n",
    "def train_step(batch_size, image, captions):\n",
    "    image, label = image, captions\n",
    "    with tf.device('/device:GPU:0'): \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      \n",
    "            noise = np.random.normal(0, 1, size=(batch_size, 256))\n",
    "\n",
    "            generated_images = generator([label, noise], training=True)\n",
    "\n",
    "            real_output = discriminator([image, label], training=True)\n",
    "\n",
    "            fake_output = discriminator([generated_images, label], training=True)\n",
    "\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        # tf.print(f'Genrator loss: {gen_loss} Discriminator loss: {disc_loss}')\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "_ZqjsQTlyBgG",
    "outputId": "c552b62e-43c2-4ed5-e09d-984d78cf2537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "(X_train, y_train), (testX, testy) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_train = (X_train - 127.5) / 127.5\n",
    "\n",
    "plt.imshow(X_train[1])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0MQf2jaWyBk6"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fit(epochs):\n",
    "    batch_size=512\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "        start = time.time()\n",
    "\n",
    "\n",
    "        for i in range(len(X_train)//batch_size):\n",
    "            image_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "            caption_batch = np.array(y_train[i*batch_size:(i+1)*batch_size])\n",
    "            train_step(batch_size, image_batch, caption_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tIOKZOY5yBnk",
    "outputId": "692ebd82-43db-4d35-af09-181246908e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "Epoch 2/1000\n",
      "Epoch 3/1000\n",
      "Epoch 4/1000\n",
      "Epoch 5/1000\n",
      "Epoch 6/1000\n",
      "Epoch 7/1000\n",
      "Epoch 8/1000\n",
      "Epoch 9/1000\n",
      "Epoch 10/1000\n",
      "Epoch 11/1000\n",
      "Epoch 12/1000\n",
      "Epoch 13/1000\n",
      "Epoch 14/1000\n",
      "Epoch 15/1000\n",
      "Epoch 16/1000\n",
      "Epoch 17/1000\n",
      "Epoch 18/1000\n",
      "Epoch 19/1000\n",
      "Epoch 20/1000\n",
      "Epoch 21/1000\n",
      "Epoch 22/1000\n",
      "Epoch 23/1000\n",
      "Epoch 24/1000\n",
      "Epoch 25/1000\n",
      "Epoch 26/1000\n",
      "Epoch 27/1000\n",
      "Epoch 28/1000\n",
      "Epoch 29/1000\n",
      "Epoch 30/1000\n",
      "Epoch 31/1000\n",
      "Epoch 32/1000\n",
      "Epoch 33/1000\n",
      "Epoch 34/1000\n",
      "Epoch 35/1000\n",
      "Epoch 36/1000\n",
      "Epoch 37/1000\n",
      "Epoch 38/1000\n",
      "Epoch 39/1000\n",
      "Epoch 40/1000\n",
      "Epoch 41/1000\n",
      "Epoch 42/1000\n",
      "Epoch 43/1000\n",
      "Epoch 44/1000\n",
      "Epoch 45/1000\n",
      "Epoch 46/1000\n",
      "Epoch 47/1000\n",
      "Epoch 48/1000\n",
      "Epoch 49/1000\n",
      "Epoch 50/1000\n",
      "Epoch 51/1000\n",
      "Epoch 52/1000\n",
      "Epoch 53/1000\n",
      "Epoch 54/1000\n",
      "Epoch 55/1000\n",
      "Epoch 56/1000\n",
      "Epoch 57/1000\n",
      "Epoch 58/1000\n",
      "Epoch 59/1000\n",
      "Epoch 60/1000\n",
      "Epoch 61/1000\n",
      "Epoch 62/1000\n",
      "Epoch 63/1000\n",
      "Epoch 64/1000\n",
      "Epoch 65/1000\n",
      "Epoch 66/1000\n",
      "Epoch 67/1000\n",
      "Epoch 68/1000\n",
      "Epoch 69/1000\n",
      "Epoch 70/1000\n",
      "Epoch 71/1000\n",
      "Epoch 72/1000\n",
      "Epoch 73/1000\n",
      "Epoch 74/1000\n",
      "Epoch 75/1000\n",
      "Epoch 76/1000\n",
      "Epoch 77/1000\n",
      "Epoch 78/1000\n",
      "Epoch 79/1000\n",
      "Epoch 80/1000\n",
      "Epoch 81/1000\n",
      "Epoch 82/1000\n",
      "Epoch 83/1000\n",
      "Epoch 84/1000\n",
      "Epoch 85/1000\n",
      "Epoch 86/1000\n",
      "Epoch 87/1000\n",
      "Epoch 88/1000\n",
      "Epoch 89/1000\n",
      "Epoch 90/1000\n",
      "Epoch 91/1000\n",
      "Epoch 92/1000\n",
      "Epoch 93/1000\n",
      "Epoch 94/1000\n",
      "Epoch 95/1000\n",
      "Epoch 96/1000\n",
      "Epoch 97/1000\n",
      "Epoch 98/1000\n",
      "Epoch 99/1000\n",
      "Epoch 100/1000\n",
      "Epoch 101/1000\n",
      "Epoch 102/1000\n",
      "Epoch 103/1000\n",
      "Epoch 104/1000\n",
      "Epoch 105/1000\n",
      "Epoch 106/1000\n",
      "Epoch 107/1000\n",
      "Epoch 108/1000\n",
      "Epoch 109/1000\n",
      "Epoch 110/1000\n",
      "Epoch 111/1000\n",
      "Epoch 112/1000\n",
      "Epoch 113/1000\n",
      "Epoch 114/1000\n",
      "Epoch 115/1000\n",
      "Epoch 116/1000\n",
      "Epoch 117/1000\n",
      "Epoch 118/1000\n",
      "Epoch 119/1000\n",
      "Epoch 120/1000\n",
      "Epoch 121/1000\n",
      "Epoch 122/1000\n",
      "Epoch 123/1000\n",
      "Epoch 124/1000\n",
      "Epoch 125/1000\n",
      "Epoch 126/1000\n",
      "Epoch 127/1000\n",
      "Epoch 128/1000\n",
      "Epoch 129/1000\n",
      "Epoch 130/1000\n",
      "Epoch 131/1000\n",
      "Epoch 132/1000\n",
      "Epoch 133/1000\n",
      "Epoch 134/1000\n",
      "Epoch 135/1000\n",
      "Epoch 136/1000\n",
      "Epoch 137/1000\n",
      "Epoch 138/1000\n",
      "Epoch 139/1000\n",
      "Epoch 140/1000\n",
      "Epoch 141/1000\n",
      "Epoch 142/1000\n",
      "Epoch 143/1000\n",
      "Epoch 144/1000\n",
      "Epoch 145/1000\n",
      "Epoch 146/1000\n",
      "Epoch 147/1000\n",
      "Epoch 148/1000\n",
      "Epoch 149/1000\n",
      "Epoch 150/1000\n",
      "Epoch 151/1000\n",
      "Epoch 152/1000\n",
      "Epoch 153/1000\n",
      "Epoch 154/1000\n",
      "Epoch 155/1000\n",
      "Epoch 156/1000\n",
      "Epoch 157/1000\n",
      "Epoch 158/1000\n",
      "Epoch 159/1000\n",
      "Epoch 160/1000\n",
      "Epoch 161/1000\n",
      "Epoch 162/1000\n",
      "Epoch 163/1000\n",
      "Epoch 164/1000\n",
      "Epoch 165/1000\n",
      "Epoch 166/1000\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-30a98b264e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-61f893689f6c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mimage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mcaption_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-29d0eb412d66>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch_size, image, captions)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# tf.print(f'Genrator loss: {gen_loss} Discriminator loss: {disc_loss}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mgradients_of_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    775\u001b[0m   return [\n\u001b[1;32m    776\u001b[0m       array_ops.reshape(\n\u001b[0;32m--> 777\u001b[0;31m           _IndexedSlicesToTensorNoWarning(grad), array_ops.shape(op.inputs[0])),\n\u001b[0m\u001b[1;32m    778\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m   ]\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m   \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m   \"\"\"\n\u001b[0;32m--> 668\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     if isinstance(\n\u001b[1;32m    670\u001b[0m         input, (sparse_tensor.SparseTensor, sparse_tensor.SparseTensorValue)):\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(name, default_name, values, skip_on_eager)\u001b[0m\n\u001b[1;32m   6435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6437\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_on_eager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6438\u001b[0m   \"\"\"Internal-only entry point for `name_scope*`.\n\u001b[1;32m   6439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_u-ru_23m3J"
   },
   "outputs": [],
   "source": [
    "save_models(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "HhoAu9ASx0a6",
    "outputId": "71c66044-97d5-4952-e3c6-5f22fab51d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb8d12a7d0>"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(generator([np.expand_dims([[9]], axis=0), np.random.normal(0, 1)])).reshape(WIDTH,HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "imOQZc7M3m3L",
    "outputId": "18977805-cefe-4e7a-e2a4-e25f29f7df14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57ffe98e90>"
      ]
     },
     "execution_count": 0,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPrUlEQVR4nO3df5BV9XnH8c+z6wKyasoPSwARf4REsW3QbmxanYbWaNGxwXRSR6Zjaaqu6WgmtraptTON004bTY1GO9F2E40kNWZM/QHN2Bqkztg0CcOqlB9iolhUEMEERwEF9sfTP/aQWXTPc9f7Oz7v18zOvXuee+55uPDh3Hu/55yvubsAvPt1tLoBAM1B2IEkCDuQBGEHkiDsQBKHNXNjE2yiT1J3MzcJpLJPe3XA99tYtZrCbmaLJN0iqVPSV939+ujxk9StX7OzatkkgMBqX1Vaq/ptvJl1SvqypHMlzZe0xMzmV/t8ABqrls/sp0t61t2fc/cDkr4laXF92gJQb7WEfbakF0f9vrVYdggz6zWzfjPrH9D+GjYHoBYN/zbe3fvcvcfde7o0sdGbA1CilrBvkzRn1O/HFMsAtKFawr5G0jwzO97MJki6SNKK+rQFoN6qHnpz90Ezu1LSwxoZervT3TfWrTMAdVXTOLu7PyTpoTr1AqCBOFwWSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kERNUzab2RZJuyUNSRp09556NAWg/moKe+G33P0ndXgeAA3E23ggiVrD7pK+a2aPm1nvWA8ws14z6zez/gHtr3FzAKpV69v4M919m5n9oqSVZva0uz82+gHu3iepT5KOsqle4/YAVKmmPbu7bytud0p6QNLp9WgKQP1VHXYz6zazIw/el3SOpA31agxAfdXyNn6GpAfM7ODzfNPd/7MuXaF9dHSG5c6jjgjre8/8QGnthfPiTR+2J972CZ/9QfwEOETVYXf35yR9sI69AGgght6AJAg7kARhB5Ig7EAShB1Ioh4nwqDB7LD4r6lz+rTS2lN/Mzdc988X/kdYP7v76bDepfigyGMO+6/ydS0eWhvwobC++Iazw/rQT3eF9WzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyz14FNnBjW9531K2H9tct3h/UbTrkvrJ85aW9prdJYdmWTwmqHLKx3WvX7k0rP/X9XnBTWj/3b71e97Xcj9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7OPU0d1dWtt8x4nhuo/8xs1hfWpH/NcwVOGc8Td8uLS2a2ggXPfaFxaH9d0H4nH2P527Mqwf2fFmaa3b4t5u2fHRsH7cjWvDevmrkhN7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2gypMTfzKkvJz0r/z6zeG6062+Lzs1fvLx/Al6dNPLgnrc68bLK3508+G6/rwq2HdOuLeb532kfj5Z04vrb18xi+E6856cEtYH37jpbCOQ1Xcs5vZnWa208w2jFo21cxWmtkzxe2UxrYJoFbjeRt/l6RFb1l2jaRV7j5P0qridwBtrGLY3f0xSW+dR2expGXF/WWSLqhzXwDqrNrP7DPcfXtx/2VJM8oeaGa9knolaZImV7k5ALWq+dt4d3ep/EwNd+9z9x537+lSfGFGAI1Tbdh3mNlMSSpud9avJQCNUG3YV0haWtxfKml5fdoB0CgVP7Ob2T2SFkqabmZbJX1O0vWS7jWzSyQ9L+nCRjbZDJ0nvy+s915d/v/ZPo/H6P9p16+G9R9edlpYP/aJTWF9eLB8nL1WwanyI9uuMAf6wClzSmtvvDc+T//NU2aF9Ymvx9fbH977RlCM535/N6oYdncvO6LjrDr3AqCBOFwWSIKwA0kQdiAJwg4kQdiBJDjFtfD0p+LTLRdOfqa09uLgUeG6qy+Nh9a0Zn1YjgeoWst75of1P779wdLa2ZNfCNc9sDT+kz+09/1h/fOPnl9aO+nP1oXrDu/bF9Z/HrFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk0oyzR1MuS9JNi+4O68d0dpXWzr3vsnDd9635YVhvqQqX0K506u85dzwW1v/gyJ8G1fjvpJJLjtoa1n/3/JtKa7+z+bPhurNu7Q/rPnAgrLcj9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kESacXYNxZcO/sikeJ6LiTaptOZdLT7jPBgrP2zG0eGqO84/Pqz/1V/Exx98rDue8nnIy6d8HlRtl3PuqLCv6gqmyj78lfjvzAcHquqpnbFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk0oyzDx+Ix02/vSc+b/uTR71YWrvt3LvCdf/hgqVh/cjV8fXTt33ihLA+6/e2lNbOOvrpcN1Pvuf+sD65o/w8fkl6bTg+r/ufXy2frvqp3TPDdb907HfC+rSOw8P6jwbK69Me3BiuO+TtfLX+6lTcs5vZnWa208w2jFp2nZltM7O1xc95jW0TQK3G8zb+LkmLxlh+s7svKH4eqm9bAOqtYtjd/TFJu5rQC4AGquULuivNbF3xNn9K2YPMrNfM+s2sf0D7a9gcgFpUG/bbJZ0oaYGk7ZK+WPZAd+9z9x537+nSxCo3B6BWVYXd3Xe4+5C7D0v6iqTT69sWgHqrKuxmNnrM5OOSNpQ9FkB7qDjObmb3SFooabqZbZX0OUkLzWyBRqYO3yLp8gb2WB/D8bnT/7h8cVhfevGtpbVFk+PvIhbd1hfWh3w4rFey3werXve14XjbT+wrP49fkv5u8++H9V0PzyqtDXx4d7ju5LnxNe0r/bkv77uqtDb79e+H674bVQy7uy8ZY/EdDegFQANxuCyQBGEHkiDsQBKEHUiCsANJpDnFtZL3/8tLYf1rHzuutHbJe+JTVDtUfkljqfIQ0vah+DTSfV4+RLVm39xw3S/d9omwPmvlK2F94JenhfWpl5a/rvec9K/huhMtPoX1A/92RVifd8MPwno27NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2QtDW7eH9eUfOq609u9TFoTr+v54nFyD8Ti7v/lmXA/W9wpTVc+w1WFdR8fj6K9dNCGs//fJ3yytTek8In7u4fjPffIX4uMbBt+Fl4OuBXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfaCD8Rj4VF9eO/eerfTPPGp9nr1t+Ppor+64Mth/YiO8lmABjw+BuBrr50c1gdfio+NwKHYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzJ2cd8UD74OFx/eQJ8fEJHSofZ988GJ+v/o1bzg3r053rwr8TFffsZjbHzB41s6fMbKOZfaZYPtXMVprZM8XtlMa3C6Ba43kbPyjpanefL+nDkq4ws/mSrpG0yt3nSVpV/A6gTVUMu7tvd/cnivu7JW2SNFvSYknLioctk3RBo5oEULt39JndzI6TdKqk1ZJmuPvBg5NfljSjZJ1eSb2SNEmTq+0TQI3G/W28mR0h6T5JV7n766Nr7u6Sxry6n7v3uXuPu/d0BV/WAGiscYXdzLo0EvS73f3+YvEOM5tZ1GdK2tmYFgHUQ8W38WZmku6QtMndbxpVWiFpqaTri9vlDekQDWWHx9Mif+hPngzrky2+lHSnle9PHt4zP1z3vQ9vDevxBbjxVuP5zH6GpIslrTeztcWyazUS8nvN7BJJz0u6sDEtAqiHimF39++p/BIHZ9W3HQCNwuGyQBKEHUiCsANJEHYgCcIOJMEprskNfvDEsH7RtLtqev4hHy6t9f34jHDdWS9sqmnbOBR7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH25DZf2hnWT5uwL6x3KD6ffb+Xn3U+++/jfc3IBZBQL+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmTO/bbFf6//2hcjq4LL0nbB8undPbHN8ZPjrpizw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSYxnfvY5kr4uaYYkl9Tn7reY2XWSLpP0SvHQa939oUY1isaY9Mi6sD6k+JzyPcPx+e6f+sNPl9Y6PJ77HfU1noNqBiVd7e5PmNmRkh43s5VF7WZ3v7Fx7QGol/HMz75d0vbi/m4z2yRpdqMbA1Bf7+gzu5kdJ+lUSauLRVea2Tozu9PMppSs02tm/WbWP6D9NTULoHrjDruZHSHpPklXufvrkm6XdKKkBRrZ839xrPXcvc/de9y9p0sT69AygGqMK+xm1qWRoN/t7vdLkrvvcPchdx+W9BVJpzeuTQC1qhh2MzNJd0ja5O43jVo+c9TDPi5pQ/3bA1Av4/k2/gxJF0tab2Zri2XXSlpiZgs0Mhy3RdLlDekQDdUxZ1ZYf3J/d1i/d1f8hq7zf9aX1rhQdHON59v470myMUqMqQM/RziCDkiCsANJEHYgCcIOJEHYgSQIO5AEl5JObmjzlrD++Xmnxk/gFc53YNrltsGeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSMG/iOKiZvSLp+VGLpkv6SdMaeGfatbd27Uuit2rVs7e57n70WIWmhv1tGzfrd/eeljUQaNfe2rUvid6q1azeeBsPJEHYgSRaHfa+Fm8/0q69tWtfEr1Vqym9tfQzO4DmafWeHUCTEHYgiZaE3cwWmdmPzOxZM7umFT2UMbMtZrbezNaaWX+Le7nTzHaa2YZRy6aa2Uoze6a4HXOOvRb1dp2ZbSteu7Vmdl6LeptjZo+a2VNmttHMPlMsb+lrF/TVlNet6Z/ZzaxT0o8lnS1pq6Q1kpa4+1NNbaSEmW2R1OPuLT8Aw8x+U9IeSV93918qln1B0i53v774j3KKu/9lm/R2naQ9rZ7Gu5itaOboacYlXSDpj9TC1y7o60I14XVrxZ79dEnPuvtz7n5A0rckLW5BH23P3R+TtOstixdLWlbcX6aRfyxNV9JbW3D37e7+RHF/t6SD04y39LUL+mqKVoR9tqQXR/2+Ve0137tL+q6ZPW5mva1uZgwz3H17cf9lSTNa2cwYKk7j3UxvmWa8bV67aqY/rxVf0L3dme5+mqRzJV1RvF1tSz7yGaydxk7HNY13s4wxzfjPtPK1q3b681q1IuzbJM0Z9fsxxbK24O7bitudkh5Q+01FvePgDLrF7c4W9/Mz7TSN91jTjKsNXrtWTn/eirCvkTTPzI43swmSLpK0ogV9vI2ZdRdfnMjMuiWdo/abinqFpKXF/aWSlrewl0O0yzTeZdOMq8WvXcunP3f3pv9IOk8j38hvlvTXreihpK8TJP1v8bOx1b1Jukcjb+sGNPLdxiWSpklaJekZSY9ImtpGvX1D0npJ6zQSrJkt6u1MjbxFXydpbfFzXqtfu6CvprxuHC4LJMEXdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8Dpseiq4BeaKEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np.array(generator([np.expand_dims([[9]], axis=0), np.random.normal(0, 1)])).reshape(WIDTH,HEIGHT)\n",
    "plt.imshow(img.reshape(28, 28))       "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seqganoriginal (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
